{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2000225,"sourceType":"datasetVersion","datasetId":576013}],"dockerImageVersionId":30162,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import models as models\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms as T\nfrom PIL import Image\nimport os\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,f1_score","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.638051Z","iopub.execute_input":"2022-03-16T08:37:55.638292Z","iopub.status.idle":"2022-03-16T08:37:55.644702Z","shell.execute_reply.started":"2022-03-16T08:37:55.638266Z","shell.execute_reply":"2022-03-16T08:37:55.643996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 128\ntransform = T.Compose([\n    T.Resize((128,128)),\n    T.ToTensor()\n])\nbatch_size = 64\nnum_epochs = 5\nfolders = ['Normal','COVID','Lung_Opacity','Viral Pneumonia']\nnum_classes = len(folders)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.649159Z","iopub.execute_input":"2022-03-16T08:37:55.649653Z","iopub.status.idle":"2022-03-16T08:37:55.655823Z","shell.execute_reply.started":"2022-03-16T08:37:55.649617Z","shell.execute_reply":"2022-03-16T08:37:55.655154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetFromImage(Dataset):\n    def __init__(self,image_folder,transform,train):\n        self.image_folder = image_folder\n        self.transform = transform\n        self.images = self.fetch_train_images() if train else self.fetch_test_images()\n        \n    def __getitem__(self,index):\n        img_path = self.images[index]\n        a = img_path.split('-')\n        img = Image.open(os.path.join(self.image_folder,a[0],self.images[index])).convert('RGB')\n        img = self.transform(img)\n        label = folders.index(a[0])\n        return img,label\n    \n    def fetch_train_images(self):\n        images = []\n        for i,x in enumerate(folders):\n            for j,y in enumerate(os.listdir(os.path.join(self.image_folder,x))):\n                if(j<1000):\n                    images.append(y)\n                else:\n                    break\n        return images\n    \n    def fetch_test_images(self):\n        images = []\n        for i,x in enumerate(folders):\n            for j,y in enumerate(os.listdir(os.path.join(self.image_folder,x))):\n                if(j>1000 and j<1300):\n                    images.append(y)\n                elif(j>1300):\n                    break\n        return images\n    \n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.657484Z","iopub.execute_input":"2022-03-16T08:37:55.657855Z","iopub.status.idle":"2022-03-16T08:37:55.673241Z","shell.execute_reply.started":"2022-03-16T08:37:55.657820Z","shell.execute_reply":"2022-03-16T08:37:55.672412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = DatasetFromImage('../input/covid19-radiography-database/COVID-19_Radiography_Dataset',transform,True)\ntrain_dl = DataLoader(train_set,batch_size,shuffle=True)\ntest_set = DatasetFromImage('../input/covid19-radiography-database/COVID-19_Radiography_Dataset',transform,False)\ntest_dl = DataLoader(test_set,256,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.676985Z","iopub.execute_input":"2022-03-16T08:37:55.677209Z","iopub.status.idle":"2022-03-16T08:37:55.705560Z","shell.execute_reply.started":"2022-03-16T08:37:55.677149Z","shell.execute_reply":"2022-03-16T08:37:55.704937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image,label in train_set:\n    plt.imshow(image.permute(1,2,0))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.706609Z","iopub.execute_input":"2022-03-16T08:37:55.706847Z","iopub.status.idle":"2022-03-16T08:37:55.912307Z","shell.execute_reply.started":"2022-03-16T08:37:55.706816Z","shell.execute_reply":"2022-03-16T08:37:55.911598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.914134Z","iopub.execute_input":"2022-03-16T08:37:55.915599Z","iopub.status.idle":"2022-03-16T08:37:55.919766Z","shell.execute_reply.started":"2022-03-16T08:37:55.915559Z","shell.execute_reply":"2022-03-16T08:37:55.918597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvNet(nn.Module):\n  def __init__(self):\n    # super here used access method of parent class\n    # dont worry much just boiler plate\n    super(ConvNet,self).__init__()\n    # In conv layer in_channels== input; out_channels=output; kernel_size=filter size\n    self.conv1=nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3)\n    # Linear layer in_features is input, how 8*31*31 came is explained in above comment\n    # out_features= output\n    self.fc1=nn.Linear(in_features=8*31*31,out_features=32)\n    self.out=nn.Linear(in_features=32,out_features=2)\n\n  def forward(self,l):\n    # this method implements forward propagation\n    # So, layers are structured as such\n\n    # 1 Conv layer\n    # may be thinking self.conv1 is an layer object instance how can we call as if it a function\n    # Checkout python documents __call__ this special method is used, so that instances behaves like function\n    # __call__ this special method invokes anytime the object instance is called. This interacts with forward method.\n    l=self.conv1(l)\n    l=F.relu(l)\n    l=F.max_pool2d(l,kernel_size=2)\n\n    # linear and final layer\n    # -1 indicates, give any number of batch size\n    l=l.reshape(-1,8*31*31)\n    l=self.fc1(l)\n    l=self.out(l)\n\n    return l","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:55.921200Z","iopub.execute_input":"2022-03-16T08:37:55.921728Z","iopub.status.idle":"2022-03-16T08:37:58.415012Z","shell.execute_reply.started":"2022-03-16T08:37:55.921690Z","shell.execute_reply":"2022-03-16T08:37:58.414352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = optim.Adam(model.parameters(),lr=0.0001)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:58.416293Z","iopub.execute_input":"2022-03-16T08:37:58.416694Z","iopub.status.idle":"2022-03-16T08:37:58.422799Z","shell.execute_reply.started":"2022-03-16T08:37:58.416657Z","shell.execute_reply":"2022-03-16T08:37:58.421851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def acc():\n    for image,label in test_dl:\n        image,label = image.to(device),label.to(device)\n        out = model(image)\n        _,out = torch.max(out,1)\n        return (torch.sum((label==out))/len(label)).item()\nacc()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:58.424179Z","iopub.execute_input":"2022-03-16T08:37:58.424592Z","iopub.status.idle":"2022-03-16T08:37:59.846120Z","shell.execute_reply.started":"2022-03-16T08:37:58.424557Z","shell.execute_reply":"2022-03-16T08:37:59.845498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = []\naccuracies = []","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:59.850482Z","iopub.execute_input":"2022-03-16T08:37:59.853064Z","iopub.status.idle":"2022-03-16T08:37:59.859071Z","shell.execute_reply.started":"2022-03-16T08:37:59.853027Z","shell.execute_reply":"2022-03-16T08:37:59.858219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for i,(image,label) in enumerate(train_dl):\n        image,label = image.to(device),label.to(device)\n        out = model(image)\n        loss = criterion(out,label)\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        if(i%5==0):\n            accuracy = acc()\n            losses.append(loss.item())\n            accuracies.append(accuracy)\n            print(epoch,i,loss.item(),accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:37:59.861803Z","iopub.execute_input":"2022-03-16T08:37:59.862336Z","iopub.status.idle":"2022-03-16T08:40:40.764508Z","shell.execute_reply.started":"2022-03-16T08:37:59.862301Z","shell.execute_reply":"2022-03-16T08:40:40.763797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(losses)\nplt.title('Loss vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('loss')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:40:40.767472Z","iopub.execute_input":"2022-03-16T08:40:40.767972Z","iopub.status.idle":"2022-03-16T08:40:40.958596Z","shell.execute_reply.started":"2022-03-16T08:40:40.767930Z","shell.execute_reply":"2022-03-16T08:40:40.957949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(accuracies)\nplt.title('Accuracy vs Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:40:40.959814Z","iopub.execute_input":"2022-03-16T08:40:40.960037Z","iopub.status.idle":"2022-03-16T08:40:41.147340Z","shell.execute_reply.started":"2022-03-16T08:40:40.960005Z","shell.execute_reply":"2022-03-16T08:40:41.146724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def con_mat():\n    for image,label in test_dl:\n        image,label = image.to(device),label.to(device)\n        out = model(image)\n        _,out = torch.max(out,1)\n        cm = confusion_matrix(out.cpu().detach().numpy().round(),label.cpu().numpy())\n        disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=folders)\n        disp.plot()\n        break\ncon_mat()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:40:41.148574Z","iopub.execute_input":"2022-03-16T08:40:41.148811Z","iopub.status.idle":"2022-03-16T08:40:42.571179Z","shell.execute_reply.started":"2022-03-16T08:40:41.148778Z","shell.execute_reply":"2022-03-16T08:40:42.570492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_f1_score():\n    for image,label in test_dl:\n        torch.cuda.empty_cache()\n        image,label = image.to(device),label.to(device)\n        out = model(image)\n        _,out = torch.max(out,1)\n        return f1_score(out.cpu().detach().numpy(),label.cpu().numpy(),average='macro')\ncalc_f1_score()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:40:42.572507Z","iopub.execute_input":"2022-03-16T08:40:42.572897Z","iopub.status.idle":"2022-03-16T08:40:43.703420Z","shell.execute_reply.started":"2022-03-16T08:40:42.572859Z","shell.execute_reply":"2022-03-16T08:40:43.702719Z"},"trusted":true},"execution_count":null,"outputs":[]}]}